{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import skimage\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from training.wandblogger import WandBLogger2D\n",
    "from training.trainer import MRTrainer\n",
    "from datasets.imagesignal import ImageSignal\n",
    "from networks.mrnet import MRFactory\n",
    "from datasets.imageutils import gaussian_pyramid2D, gaussian_tower2D, box_kernel2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"l-net.ipynb\"\n",
    "BASE_DIR = Path('.').absolute().parents[0]\n",
    "IMAGE_PATH = BASE_DIR.joinpath('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"cameraman_baseX\"\n",
    "# hyperparameters\n",
    "hyper = {'omega_0': 32,\n",
    "         'in_features': 2,\n",
    "         'hidden_features': 256,\n",
    "         'hidden_layers': 3,\n",
    "         'superposition_w0': True,\n",
    "         'hidden_omega_0': 30,\n",
    "\n",
    "         'sampling_scheme': 'uniform',\n",
    "         'multiresolution': 'capacity',\n",
    "         \n",
    "         'max_epochs_per_stage': 200,\n",
    "         'opt_method': 'Adam',\n",
    "         'loss_function': 'd0_MSE',\n",
    "         'lr': 1e-4,\n",
    "         'loss_tol': 1e-14,\n",
    "         'diff_tol': 0.00000000001,\n",
    "         'batch_size': 1,\n",
    "         \n",
    "         'image_name': 'camera.png',\n",
    "         'width': 512,\n",
    "         'height': 512,\n",
    "         'channels': 1,\n",
    "\n",
    "         'stage': 1,\n",
    "         'max_stages': 1,\n",
    "         'model': 'L',\n",
    "         'useattributes': False,\n",
    "         'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "         'eval_device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        #  'extrapolate': [-3, 3],\n",
    "        #  'save_format': 'general',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = hyper['batch_size']\n",
    "kernel = box_kernel2D(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_signal = ImageSignal.init_fromfile(\n",
    "                    os.path.join(IMAGE_PATH, hyper['image_name']),\n",
    "                    useattributes=hyper.get('useattributes', False))\n",
    "# incluir parametro batch_pixels - aqui e no dicionario acima\n",
    "hyper['width'], hyper['height'] = base_signal.dimensions()\n",
    "if hyper['multiresolution'] == 'capacity':\n",
    "    train_dataloader = DataLoader(base_signal, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=0)\n",
    "    test_dataloader = DataLoader(base_signal, batch_size=BATCH_SIZE, pin_memory=True, num_workers=0)\n",
    "else:\n",
    "    pyramid = gaussian_pyramid2D(base_signal, hyper['max_stages'], kernel)\n",
    "    tower = gaussian_tower2D(base_signal, hyper['max_stages'], kernel)\n",
    "    trainsource = pyramid if hyper['multiresolution'] == 'pyramid' else tower\n",
    "    train_dataloader = [DataLoader(signal, shuffle=True, batch_size=BATCH_SIZE) \n",
    "                        for signal in trainsource]\n",
    "    test_dataloader = [DataLoader(signal, batch_size=BATCH_SIZE) \n",
    "                        for signal in tower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'networks.mrnet.LNet'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlvelho\u001b[0m (\u001b[33msiren-song\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Workspace\\mrimg\\src\\wandb\\run-20220810_111708-1h5ymrs9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/siren-song/cameraman_baseX/runs/1h5ymrs9\" target=\"_blank\">LCcame__1/1_w32T_hf256_MEp200_hl3_d0_512px</a></strong> to <a href=\"https://wandb.ai/siren-song/cameraman_baseX\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>D0 loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>D0 loss</td><td>0.00236</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">LCcame__1/1_w32T_hf256_MEp200_hl3_d0_512px</strong>: <a href=\"https://wandb.ai/siren-song/cameraman_baseX/runs/1h5ymrs9\" target=\"_blank\">https://wandb.ai/siren-song/cameraman_baseX/runs/1h5ymrs9</a><br/>Synced 4 W&B file(s), 6 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220810_111708-1h5ymrs9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished after 200 epochs\n"
     ]
    }
   ],
   "source": [
    "wandblogger = WandBLogger2D(project_name,\n",
    "                            f\"{hyper['model']}{hyper['multiresolution'][0].upper()}{hyper['image_name'][0:4]}_\",\n",
    "                            hyper,\n",
    "                            BASE_DIR)\n",
    "mrmodel = MRFactory.from_dict(hyper)\n",
    "print(\"Model: \", type(mrmodel))\n",
    "mrtrainer = MRTrainer.init_from_dict(mrmodel, train_dataloader, test_dataloader, wandblogger, hyper)\n",
    "mrtrainer.train(hyper['device'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49e853727b9044d2183398b4abf82bbfe6cc31cdffab7d7757c6a329071b655c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
