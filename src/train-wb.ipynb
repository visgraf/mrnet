{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from logs.wandblogger import WandBLogger2D\n",
    "from training.trainer import MRTrainer\n",
    "from datasets.signals import ImageSignal#, make_mask\n",
    "from networks.mrnet import MRFactory\n",
    "from datasets.pyramids import create_MR_structure\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"train-wb.ipynb\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "BASE_DIR = Path('.').absolute().parents[0]\n",
    "IMAGE_PATH = BASE_DIR.joinpath('img')\n",
    "MODEL_PATH = BASE_DIR.joinpath('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'M', 'positive_freqs': False, 'in_features': 2, 'out_features': 3, 'hidden_layers': 3, 'hidden_features': [256], 'bias': True, 'max_stages': 1, 'period': 2, 'pmode': 'wrap', 'domain': [-1, 1], 'omega_0': [30, 3, 6, 12, 18, 32, 64], 'hidden_omega_0': [30, 30, 30, 30, 30, 30, 30], 'superposition_w0': False, 'sampling_scheme': 'regular', 'decimation': True, 'filter': 'gauss', 'attributes': ['d0', 'd1'], 'loss_function': 'hermite', 'loss_weights': {'d0': 1, 'd1': 0.0}, 'opt_method': 'Adam', 'lr': 0.0001, 'loss_tol': 1e-12, 'diff_tol': 1e-05, 'max_epochs_per_stage': [10], 'batch_size': 131072, 'image_name': 'siggraph_asia/leopard.jpg', 'width': 512, 'height': 512, 'channels': 3, 'color_space': 'RGB', 'device': 'cuda', 'eval_device': 'cpu', 'save_format': 'general', 'visualize_grad': True, 'extrapolate': [-2, 2], 'zoom': [2, 4], 'zoom_filters': ['linear', 'cubic', 'nearest']}\n"
     ]
    }
   ],
   "source": [
    "project_name = \"dev-sandbox\"\n",
    "#-- hyperparameters in configs --#\n",
    "config_file = '../configs/config_siggraph_siren.yml'\n",
    "with open(config_file) as f:\n",
    "    hyper = yaml.load(f, Loader=SafeLoader)\n",
    "    if isinstance(hyper['batch_size'], str):\n",
    "        hyper['batch_size'] = eval(hyper['batch_size'])\n",
    "    if hyper.get('channels', 0) == 0:\n",
    "            hyper['channels'] = hyper['out_features']\n",
    "    print(hyper)\n",
    "imgpath = os.path.join(IMAGE_PATH, hyper['image_name'])\n",
    "maskpath = None\n",
    "# maskpath = \"/Users/hallpaz/Workspace/impa/mrimg/img/synthetic/mask_inverted.png\" #make_mask(imgpath, hyper['mask_color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_signal = ImageSignal.init_fromfile(\n",
    "                    imgpath,\n",
    "                    domain=hyper['domain'],\n",
    "                    channels=hyper['channels'],\n",
    "                    sampling_scheme=hyper['sampling_scheme'],\n",
    "                    width=hyper['width'], height=hyper['height'],\n",
    "                    attributes=hyper['attributes'],\n",
    "                    batch_size=hyper['batch_size'],\n",
    "                    color_space=hyper['color_space'])\n",
    "\n",
    "train_dataset = create_MR_structure(base_signal, \n",
    "                                       hyper['max_stages'], \n",
    "                                       hyper['filter'], \n",
    "                                       hyper['decimation'],\n",
    "                                       hyper['pmode'])\n",
    "test_dataset = create_MR_structure(base_signal, \n",
    "                                      hyper['max_stages'], \n",
    "                                      hyper['filter'], \n",
    "                                      False,\n",
    "                                      hyper['pmode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datashape = test_loader.shape[1:]\n",
    "# coords = make_grid_coords(datashape, \n",
    "#                             *self.hyper['domain'],\n",
    "#                             len(datashape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  <class 'networks.mrnet.MNet'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhallpaz\u001b[0m (\u001b[33msiren-song\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\Workspace\\impa\\mrnet\\src\\wandb\\run-20230520_002837-n1td9mj6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/siren-song/dev-sandbox/runs/n1td9mj6' target=\"_blank\">MGleopa_1/1_w30F_hf256_MEp10_hl3_r512_pr2</a></strong> to <a href='https://wandb.ai/siren-song/dev-sandbox' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/siren-song/dev-sandbox' target=\"_blank\">https://wandb.ai/siren-song/dev-sandbox</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/siren-song/dev-sandbox/runs/n1td9mj6' target=\"_blank\">https://wandb.ai/siren-song/dev-sandbox/runs/n1td9mj6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SIZE torch.Size([3, 512, 512])\n",
      "RGB COLOR SPACE\n",
      "RGB COLOR SPACE\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 134217728 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32me:\\Workspace\\impa\\mrnet\\src\\train-wb.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workspace/impa/mrnet/src/train-wb.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m wandblogger \u001b[39m=\u001b[39m WandBLogger2D(project_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workspace/impa/mrnet/src/train-wb.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mhyper[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mhyper[\u001b[39m'\u001b[39m\u001b[39mfilter\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mupper()\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mimg_name[\u001b[39m0\u001b[39m:\u001b[39m5\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workspace/impa/mrnet/src/train-wb.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                             hyper,\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workspace/impa/mrnet/src/train-wb.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                             BASE_DIR)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workspace/impa/mrnet/src/train-wb.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m mrtrainer \u001b[39m=\u001b[39m MRTrainer\u001b[39m.\u001b[39minit_from_dict(mrmodel, \n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Workspace/impa/mrnet/src/train-wb.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                      train_dataset, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Workspace/impa/mrnet/src/train-wb.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                      test_dataset, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Workspace/impa/mrnet/src/train-wb.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                      wandblogger, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Workspace/impa/mrnet/src/train-wb.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                                      hyper)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Workspace/impa/mrnet/src/train-wb.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m mrtrainer\u001b[39m.\u001b[39;49mtrain(hyper[\u001b[39m'\u001b[39;49m\u001b[39mdevice\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32me:\\Workspace\\impa\\mrnet\\src\\training\\trainer.py:307\u001b[0m, in \u001b[0;36mMRTrainer.train\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    306\u001b[0m     optimizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger\u001b[39m.\u001b[39;49mon_stage_trained(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_model(), \n\u001b[0;32m    308\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_dataloader,\n\u001b[0;32m    309\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_testloader)\n\u001b[0;32m    311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mon_train_finish(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model(), \n\u001b[0;32m    312\u001b[0m                             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_epochs_trained)\n",
      "File \u001b[1;32me:\\Workspace\\impa\\mrnet\\src\\logs\\wandblogger.py:360\u001b[0m, in \u001b[0;36mWandBLogger2D.on_stage_trained\u001b[1;34m(self, current_model, train_loader, test_loader)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_traindata(train_loader)\n\u001b[0;32m    359\u001b[0m gt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_groundtruth(test_loader)\n\u001b[1;32m--> 360\u001b[0m pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_prediction(current_model, test_loader, device)\n\u001b[0;32m    361\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_PSNR(gt\u001b[39m.\u001b[39mto(device), pred\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m    362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_SSIM(gt\u001b[39m.\u001b[39mcpu(), pred\u001b[39m.\u001b[39mcpu())\n",
      "File \u001b[1;32me:\\Workspace\\impa\\mrnet\\src\\logs\\wandblogger.py:432\u001b[0m, in \u001b[0;36mWandBLogger2D.log_prediction\u001b[1;34m(self, model, test_loader, device)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m BatchSampler(coords, \n\u001b[0;32m    429\u001b[0m                           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyper[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m    430\u001b[0m                           drop_last\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    431\u001b[0m     batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(batch)\n\u001b[1;32m--> 432\u001b[0m     output_dict \u001b[39m=\u001b[39m model(batch\u001b[39m.\u001b[39;49mto(device))\n\u001b[0;32m    433\u001b[0m     pixels\u001b[39m.\u001b[39mappend(output_dict[\u001b[39m'\u001b[39m\u001b[39mmodel_out\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu())\n\u001b[0;32m    434\u001b[0m     value \u001b[39m=\u001b[39m output_dict[\u001b[39m'\u001b[39m\u001b[39mmodel_out\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32me:\\Workspace\\impa\\siren-song\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1128\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1125\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[0;32m   1126\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1128\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1130\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[1;32me:\\Workspace\\impa\\mrnet\\src\\networks\\mrnet.py:262\u001b[0m, in \u001b[0;36mMNet.forward\u001b[1;34m(self, coords, mrweights)\u001b[0m\n\u001b[0;32m    260\u001b[0m basis \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[39mfor\u001b[39;00m mrstage \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstages:\n\u001b[1;32m--> 262\u001b[0m     out, basis \u001b[39m=\u001b[39m mrstage(coords, basis)\n\u001b[0;32m    263\u001b[0m     mroutputs\u001b[39m.\u001b[39mappend(out)\n\u001b[0;32m    264\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_resolutions(mroutputs, mrweights)\n",
      "File \u001b[1;32me:\\Workspace\\impa\\siren-song\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Workspace\\impa\\mrnet\\src\\networks\\mrnet.py:101\u001b[0m, in \u001b[0;36mMRModule.forward\u001b[1;34m(self, coords, prevbasis)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, coords, prevbasis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    100\u001b[0m     proj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_layer(coords)\n\u001b[1;32m--> 101\u001b[0m     basis \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmiddle_layers(proj) \u001b[39mif\u001b[39;00m prevbasis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \n\u001b[0;32m    102\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle_layers(torch\u001b[39m.\u001b[39mcat([proj, prevbasis], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) )\n\u001b[0;32m    103\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_linear(basis)\n\u001b[0;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m out, basis\n",
      "File \u001b[1;32me:\\Workspace\\impa\\siren-song\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Workspace\\impa\\siren-song\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32me:\\Workspace\\impa\\siren-song\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Workspace\\impa\\mrnet\\src\\networks\\siren.py:86\u001b[0m, in \u001b[0;36mSineLayer.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     84\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(\u001b[39minput\u001b[39m)\n\u001b[0;32m     85\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39momega_0 \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m     87\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39msin(x)\n",
      "File \u001b[1;32me:\\Workspace\\impa\\siren-song\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Workspace\\impa\\siren-song\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 134217728 bytes."
     ]
    }
   ],
   "source": [
    "img_name = os.path.basename(hyper['image_name'])\n",
    "mrmodel = MRFactory.from_dict(hyper)\n",
    "print(\"Model: \", type(mrmodel))\n",
    "wandblogger = WandBLogger2D(project_name,\n",
    "                            f\"{hyper['model']}{hyper['filter'][0].upper()}{img_name[0:5]}\",\n",
    "                            hyper,\n",
    "                            BASE_DIR)\n",
    "mrtrainer = MRTrainer.init_from_dict(mrmodel, \n",
    "                                     train_dataset, \n",
    "                                     test_dataset, \n",
    "                                     wandblogger, \n",
    "                                     hyper)\n",
    "mrtrainer.train(hyper['device'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18fae99c00fc8e14a15ff5b63f2ba50919b3e541fb0c0acba9c6dcfa2727f204"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
