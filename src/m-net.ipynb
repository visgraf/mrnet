{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import skimage\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from training.wandblogger import WandBLogger2D\n",
    "from training.trainer import MRTrainer\n",
    "from datasets.imagesignal import ImageSignal\n",
    "from networks.mrnet import MRFactory\n",
    "from datasets.imageutils import gaussian_pyramid2D, gaussian_tower2D, box_kernel2D\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"m-net.ipynb\"\n",
    "BASE_DIR = Path('.').absolute().parents[0]\n",
    "IMAGE_PATH = BASE_DIR.joinpath('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'omega_0': [4, 8, 16, 32, 64, 128], 'in_features': 2, 'hidden_features': '-48 -64 -64 -128 -128 -256', 'hidden_layers': 1, 'superposition_w0': False, 'hidden_omega_0': '-30 -40 -50 -60 -70 -80', 'sampling_scheme': 'uniform', 'multiresolution': 'pyramid', 'max_epochs_per_stage': '-500 -450 -350 -250 -150 -100', 'opt_method': 'Adam', 'loss_function': 'd0_MSE', 'lr': 0.0001, 'loss_tol': 1e-14, 'diff_tol': 1e-11, 'batch_size': 16641, 'image_name': 'lena257.png', 'width': 129, 'height': 129, 'channels': 1, 'stage': 1, 'max_stages': 6, 'model': 'M', 'useattributes': True, 'device': 'cuda', 'eval_device': 'cuda'}\n"
     ]
    }
   ],
   "source": [
    "project_name = \"testing_dictionary_test\"\n",
    "# hyperparameters\n",
    "# hyperparameters\n",
    "with open('../configs/config_base_m_net.yml') as f:\n",
    "    hyper = yaml.load(f, Loader=SafeLoader)\n",
    "    print(hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = hyper['batch_size']\n",
    "kernel = box_kernel2D(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_signal = ImageSignal.init_fromfile(\n",
    "                    os.path.join(IMAGE_PATH, hyper['image_name']),\n",
    "                    useattributes=hyper.get('useattributes', False),\n",
    "                    batch_pixels=hyper['batch_size'],\n",
    "                    width=hyper['width'],height= hyper['height'])\n",
    "if hyper['multiresolution'] == 'capacity':\n",
    "    train_dataloader = DataLoader(base_signal, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=0)\n",
    "    test_dataloader = DataLoader(base_signal, batch_size=BATCH_SIZE, pin_memory=True, num_workers=0)\n",
    "else:\n",
    "    pyramid = gaussian_pyramid2D(base_signal, hyper['max_stages'], kernel)\n",
    "    tower = gaussian_tower2D(base_signal, hyper['max_stages'], kernel)\n",
    "    trainsource = pyramid if hyper['multiresolution'] == 'pyramid' else tower\n",
    "    train_dataloader = [DataLoader(signal, shuffle=True, batch_size=BATCH_SIZE) \n",
    "                        for signal in trainsource]\n",
    "    test_dataloader = [DataLoader(signal, batch_size=BATCH_SIZE) \n",
    "                        for signal in tower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/danperazzo/Desktop/IMPA_luiz_project/mrimg/src/m-net.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/danperazzo/Desktop/IMPA_luiz_project/mrimg/src/m-net.ipynb#ch0000005?line=0'>1</a>\u001b[0m wandblogger \u001b[39m=\u001b[39m WandBLogger2D(project_name,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/danperazzo/Desktop/IMPA_luiz_project/mrimg/src/m-net.ipynb#ch0000005?line=1'>2</a>\u001b[0m                             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mhyper[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mhyper[\u001b[39m'\u001b[39m\u001b[39mmultiresolution\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mupper()\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mhyper[\u001b[39m'\u001b[39m\u001b[39mimage_name\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m:\u001b[39m4\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/danperazzo/Desktop/IMPA_luiz_project/mrimg/src/m-net.ipynb#ch0000005?line=2'>3</a>\u001b[0m                             hyper,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/danperazzo/Desktop/IMPA_luiz_project/mrimg/src/m-net.ipynb#ch0000005?line=3'>4</a>\u001b[0m                             BASE_DIR)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/danperazzo/Desktop/IMPA_luiz_project/mrimg/src/m-net.ipynb#ch0000005?line=4'>5</a>\u001b[0m mrmodel \u001b[39m=\u001b[39m MRFactory\u001b[39m.\u001b[39;49mfrom_dict(hyper)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/danperazzo/Desktop/IMPA_luiz_project/mrimg/src/m-net.ipynb#ch0000005?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m(mrmodel))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/danperazzo/Desktop/IMPA_luiz_project/mrimg/src/m-net.ipynb#ch0000005?line=6'>7</a>\u001b[0m mrtrainer \u001b[39m=\u001b[39m MRTrainer\u001b[39m.\u001b[39minit_from_dict(mrmodel, train_dataloader, test_dataloader, wandblogger, hyper)\n",
      "File \u001b[0;32m~/Desktop/IMPA_luiz_project/mrimg/src/networks/mrnet.py:326\u001b[0m, in \u001b[0;36mMRFactory.from_dict\u001b[0;34m(hyper)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodel should be in [\u001b[39m\u001b[39m'\u001b[39m\u001b[39mM\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39mM1\u001b[39m\u001b[39m'\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    325\u001b[0m hfeat, hlayers \u001b[39m=\u001b[39m hyper[\u001b[39m'\u001b[39m\u001b[39mhidden_features\u001b[39m\u001b[39m'\u001b[39m], hyper[\u001b[39m'\u001b[39m\u001b[39mhidden_layers\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 326\u001b[0m \u001b[39mreturn\u001b[39;00m  MRClass(\n\u001b[1;32m    327\u001b[0m     hyper\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39min_features\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[1;32m    328\u001b[0m     hfeat[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(hfeat, Sequence) \u001b[39melse\u001b[39;49;00m hfeat,\n\u001b[1;32m    329\u001b[0m     hlayers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(hlayers, Sequence) \u001b[39melse\u001b[39;49;00m hlayers,\n\u001b[1;32m    330\u001b[0m     hyper\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mout_features\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[1;32m    331\u001b[0m     omega0[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(omega0, Sequence) \u001b[39melse\u001b[39;49;00m omega0,\n\u001b[1;32m    332\u001b[0m     hidden_omega0[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(hidden_omega0, Sequence) \u001b[39melse\u001b[39;49;00m hidden_omega0,\n\u001b[1;32m    333\u001b[0m     bias\u001b[39m=\u001b[39;49mhyper\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mbias\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    334\u001b[0m     superposition_w0\u001b[39m=\u001b[39;49mhyper\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39msuperposition_w0\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    335\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/IMPA_luiz_project/mrimg/src/networks/mrnet.py:104\u001b[0m, in \u001b[0;36mMRNet.__init__\u001b[0;34m(self, in_features, hidden_features, hidden_layers, out_features, first_omega_0, hidden_omega_0, bias, superposition_w0)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features \u001b[39m=\u001b[39m in_features\n\u001b[1;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_features \u001b[39m=\u001b[39m out_features\n\u001b[0;32m--> 104\u001b[0m first_module \u001b[39m=\u001b[39m MRModule(in_features, \n\u001b[1;32m    105\u001b[0m                         hidden_features, \n\u001b[1;32m    106\u001b[0m                         hidden_layers, \n\u001b[1;32m    107\u001b[0m                         out_features,\n\u001b[1;32m    108\u001b[0m                         first_omega_0, \n\u001b[1;32m    109\u001b[0m                         hidden_omega_0,\n\u001b[1;32m    110\u001b[0m                         bias\u001b[39m=\u001b[39;49mbias)\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstages \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([first_module])\n",
      "File \u001b[0;32m~/Desktop/IMPA_luiz_project/mrimg/src/networks/mrnet.py:26\u001b[0m, in \u001b[0;36mMRModule.__init__\u001b[0;34m(self, in_features, hidden_features, hidden_layers, out_features, first_omega_0, hidden_omega_0, bias, prevknowledge)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, in_features: \u001b[39mint\u001b[39m, \n\u001b[1;32m     17\u001b[0m                 hidden_features: \u001b[39mint\u001b[39m, \n\u001b[1;32m     18\u001b[0m                 hidden_layers: \u001b[39mint\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \n\u001b[1;32m     23\u001b[0m                 prevknowledge\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m     24\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirst_layer \u001b[39m=\u001b[39m SineLayer(in_features, hidden_features, bias\u001b[39m=\u001b[39;49mbias,\n\u001b[1;32m     27\u001b[0m                               is_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, omega_0\u001b[39m=\u001b[39;49mfirst_omega_0)\n\u001b[1;32m     29\u001b[0m     middle \u001b[39m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m     middle\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     31\u001b[0m         SineLayer(prevknowledge \u001b[39m+\u001b[39m hidden_features, hidden_features,\n\u001b[1;32m     32\u001b[0m                             is_first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, omega_0\u001b[39m=\u001b[39mhidden_omega_0)\n\u001b[1;32m     33\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/IMPA_luiz_project/mrimg/src/networks/siren.py:27\u001b[0m, in \u001b[0;36mSineLayer.__init__\u001b[0;34m(self, in_features, out_features, bias, is_first, omega_0)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features \u001b[39m=\u001b[39m in_features\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_features \u001b[39m=\u001b[39m out_features\n\u001b[0;32m---> 27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mLinear(in_features, out_features, bias\u001b[39m=\u001b[39;49mbias)\n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_weights()\n",
      "File \u001b[0;32m~/anaconda3/envs/mrnet/lib/python3.8/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features \u001b[39m=\u001b[39m in_features\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_features \u001b[39m=\u001b[39m out_features\n\u001b[0;32m---> 96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39;49mempty((out_features, in_features), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs))\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m bias:\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(out_features, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "wandblogger = WandBLogger2D(project_name,\n",
    "                            f\"{hyper['model']}{hyper['multiresolution'][0].upper()}{hyper['image_name'][0:4]}_\",\n",
    "                            hyper,\n",
    "                            BASE_DIR)\n",
    "mrmodel = MRFactory.from_dict(hyper)\n",
    "print(\"Model: \", type(mrmodel))\n",
    "mrtrainer = MRTrainer.init_from_dict(mrmodel, train_dataloader, test_dataloader, wandblogger, hyper)\n",
    "mrtrainer.train(hyper['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mrnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7057bd23362eedcba26383b73e23bddaaadbcc06d76ace968443b3bdf4612ccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
