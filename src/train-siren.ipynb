{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import skimage\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, Compose, ToTensor, Normalize\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from logging_module.wandblogger import WandBLogger2D\n",
    "from training.trainer import MRTrainer\n",
    "from datasets.imagesignal import ImageSignal\n",
    "from networks.mrnet import MRFactory\n",
    "from networks.siren import Siren\n",
    "from datasets.pyramids import create_MR_structure\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from training.loss import gradient\n",
    "from datasets.sampling import make2Dcoords\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MR-Net Config & Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"s-net.ipynb\"\n",
    "BASE_DIR = Path('.').absolute().parents[0]\n",
    "IMAGE_PATH = BASE_DIR.joinpath('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"test_sgrad\"\n",
    "\n",
    "with open('../configs/config_base_l_net.yml') as f:\n",
    "    hyper = yaml.load(f, Loader=SafeLoader)\n",
    "    print(hyper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_signal = ImageSignal.init_fromfile(\n",
    "                    os.path.join(IMAGE_PATH, hyper['image_name']),\n",
    "                    useattributes=hyper.get('useattributes', False),\n",
    "                    batch_pixels_perc=1,\n",
    "                    width=hyper['width'],height= hyper['height'])\n",
    "hyper['width'], hyper['height'] = base_signal.dimensions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIREN Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mgrid(sidelen, dim=2):\n",
    "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
    "    mgrid = torch.stack(torch.meshgrid(*tensors, indexing='ij'), dim=-1)\n",
    "    mgrid = mgrid.reshape(-1, dim)\n",
    "    return mgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cameraman_tensor(sidelength):\n",
    "    img = Image.fromarray(skimage.data.camera())        \n",
    "    transform = Compose([\n",
    "        Resize(sidelength),\n",
    "        ToTensor()\n",
    "    ])\n",
    "    img = transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "    \n",
    "class PoissonEqn(Dataset):\n",
    "    def __init__(self, sidelength):\n",
    "        super().__init__()\n",
    "        img = get_cameraman_tensor(sidelength)\n",
    "        \n",
    "        # Compute gradient and laplacian       \n",
    "        grads_x = scipy.ndimage.sobel(img.numpy(), axis=1).squeeze(0)[..., None]\n",
    "        grads_y = scipy.ndimage.sobel(img.numpy(), axis=2).squeeze(0)[..., None]\n",
    "        grads_x, grads_y = torch.from_numpy(grads_x), torch.from_numpy(grads_y)\n",
    "                \n",
    "        self.grads = torch.stack((grads_x, grads_y), dim=-1).view(-1, 2)\n",
    "        \n",
    "        self.pixels = img.permute(1, 2, 0).view(-1, 1)\n",
    "        self.coords = get_mgrid(sidelength, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'coords': self.coords}, {'d0':self.pixels, 'd1':self.grads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraman = PoissonEqn(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_signal or cameraman\n",
    "dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIREN Net & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "poisson_siren = Siren(in_features=2, out_features=1, first_omega_0=30, hidden_omega_0= 30, hidden_features=256, hidden_layers=3, outermost_linear=True)\n",
    "poisson_siren.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_mse(model_output, coords, gt_gradients):\n",
    "    # compute gradients on the model\n",
    "    gradients = gradient(model_output, coords)\n",
    "    gt_grads = gt_gradients.view(1,-1,2)\n",
    "    # compare them with the ground-truth\n",
    "    gradients_loss = torch.mean((gradients - gt_grads).pow(2).sum(-1))\n",
    "    return gradients_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = 100\n",
    "steps_til_summary = 10\n",
    "\n",
    "optim = torch.optim.Adam(lr=1e-4, params=poisson_siren.parameters())\n",
    "\n",
    "model_input, gt = next(iter(dataloader))\n",
    "gt = {key: value.cuda() for key, value in gt.items()}\n",
    "model_input = model_input['coords'].cuda()\n",
    "\n",
    "for step in range(total_steps):\n",
    "\n",
    "    model_output, coords = poisson_siren(model_input)\n",
    "    train_loss = gradients_mse(model_output, coords, gt['d1'])\n",
    "\n",
    "    if not step % steps_til_summary:\n",
    "        print(\"Step %d, Total loss %0.6f\" % (step, train_loss))\n",
    "\n",
    "        img_grad = gradient(model_output, coords)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "        axes[0].imshow(model_output.cpu().view(128,128).detach().numpy())\n",
    "        axes[1].imshow(img_grad.cpu().norm(dim=-1).view(128,128).detach().numpy())\n",
    "        plt.show()\n",
    "        \n",
    "    optim.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optim.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mrnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7057bd23362eedcba26383b73e23bddaaadbcc06d76ace968443b3bdf4612ccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
