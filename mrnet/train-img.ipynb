{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from logs.wandblogger import WandBLogger2D\n",
    "from training.trainer import MRTrainer\n",
    "from datasets.signals import ImageSignal#, make_mask\n",
    "from networks.mrnet import MRFactory\n",
    "from datasets.pyramids import create_MR_structure\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"train-wb.ipynb\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "BASE_DIR = Path('.').absolute().parents[0]\n",
    "IMAGE_PATH = BASE_DIR.joinpath('img')\n",
    "MODEL_PATH = BASE_DIR.joinpath('models')\n",
    "torch.manual_seed(777)\n",
    "\n",
    "#-- hyperparameters in configs --#\n",
    "config_file = '../configs/siggraph_asia/config_siggraph_imgs.yml'\n",
    "with open(config_file) as f:\n",
    "    hyper = yaml.load(f, Loader=SafeLoader)\n",
    "    if isinstance(hyper['batch_size'], str):\n",
    "        hyper['batch_size'] = eval(hyper['batch_size'])\n",
    "    if hyper.get('channels', 0) == 0:\n",
    "            hyper['channels'] = hyper['out_features']\n",
    "    print(hyper)\n",
    "imgpath = os.path.join(IMAGE_PATH, hyper['image_name'])\n",
    "project_name = hyper.get('project_name', 'dev_sandbox')\n",
    "maskpath = None\n",
    "# maskpath = \"/Users/hallpaz/Workspace/impa/mrimg/img/synthetic/mask_inverted.png\" #make_mask(imgpath, hyper['mask_color'])\n",
    "hyper['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_signal = ImageSignal.init_fromfile(\n",
    "                    imgpath,\n",
    "                    domain=hyper['domain'],\n",
    "                    channels=hyper['channels'],\n",
    "                    sampling_scheme=hyper['sampling_scheme'],\n",
    "                    width=hyper['width'], height=hyper['height'],\n",
    "                    attributes=hyper['attributes'],\n",
    "                    batch_size=hyper['batch_size'],\n",
    "                    color_space=hyper['color_space'])\n",
    "\n",
    "train_dataset = create_MR_structure(base_signal, \n",
    "                                       hyper['max_stages'], \n",
    "                                       hyper['filter'], \n",
    "                                       hyper['decimation'],\n",
    "                                       hyper['pmode'])\n",
    "test_dataset = create_MR_structure(base_signal, \n",
    "                                      hyper['max_stages'], \n",
    "                                      hyper['filter'], \n",
    "                                      False,\n",
    "                                      hyper['pmode'])\n",
    "\n",
    "if hyper['width'] == 0:\n",
    "    hyper['width'] = base_signal.shape[-1]\n",
    "if hyper['height'] == 0:\n",
    "    hyper['height'] = base_signal.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "mask_path = \"E:\\Workspace\\impa\\mrnet\\img\\masks\\sanity{}.png\"\n",
    "for i in range(len(train_dataset)):\n",
    "    w = train_dataset[i].shape[1]\n",
    "    tst_mask = Image.open(mask_path.format(w))\n",
    "    tst_mask = to_tensor(tst_mask).squeeze(0).bool()\n",
    "    train_dataset[i].domain_mask = tst_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = os.path.basename(hyper['image_name'])\n",
    "mrmodel = MRFactory.from_dict(hyper)\n",
    "print(\"Model: \", type(mrmodel))\n",
    "wandblogger = WandBLogger2D(project_name,\n",
    "                            f\"{hyper['model']}{hyper['filter'][0].upper()}{img_name[0:5]}{hyper['color_space'][0]}\",\n",
    "                            hyper,\n",
    "                            BASE_DIR)\n",
    "mrtrainer = MRTrainer.init_from_dict(mrmodel, \n",
    "                                     train_dataset, \n",
    "                                     test_dataset, \n",
    "                                     wandblogger, \n",
    "                                     hyper)\n",
    "mrtrainer.train(hyper['device'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2ffeedc6d441f2d043b16e3599ccecd6d9c6c91778ec3262e5caa4d87559f4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
